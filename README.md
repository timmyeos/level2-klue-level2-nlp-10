## 📋 Report  
[NLP] 문장 내 개체간 관계 추출 대회 WrapUP 리포트(PDF 파일 다운로드) : [KLUE_NLP_팀 리포트(10조).pdf](https://github.com/boostcampaitech3/level2-klue-level2-nlp-10/files/8513550/KLUE_NLP_.10.pdf)

</br>

## 💯 Feedback
<details markdown="1"> 
<summary> <b>WrapUP 리포트 피드백 접기/펼치기</b> </summary>

</br>

**이가람 멘토님**

1.종합의견
Level1 대회에서는 협업하는 측면에서 아쉬움이 있었던 캠퍼분들이 다소 계셨는데 이번 대회에서는 보다 나은 협업 방식에 대해서 여러가지로 고민하고 협업 툴도 적극적으로 활용하여 좋은 성과로 이어진 것 같습니다. 이번에 경험한 서로의 장점과 강점을 바탕으로 앞으로의 대회에서도 좋은 팀웤이 이루어지길 기대합니다.

2.우수한 점
-프로젝트 수행 task 별로 어느 정도의 기간동안 어떤 형태로 이루어졌는지 상세하게 드러나있어 주어진 기간을 효율적으로 활용하신 점이 전달되는 것 같습니다.
-Imbalanced된 데이터 문제를 해결하기 위해 back translation 등의 data augmentation 기법을 적극적으로 잘 활용해주신 것 같습니다.
-논문을 통해 충분히 사전 조사를 하고 프로젝트에 임하셨다는 것이 느껴졌습니다.
-협업 툴을 사전에 정하고 학습하는 과정을 통해 효율적인 진행이 가능했던 것 같습니다.
-데이터를 하나하나 뜯어보면서 태깅에 오류가 있는 점에 대해 해결방법을 다각도로 시도해보신 것 같습니다.


3.아쉬운 점
-<중요> 가장 중요한 점은 실험에서 각각의 방식을 어떤 이유로 고려했는지(예를 들어, 논문에서 이 방식이 어떤 장점이 있다고 소개되어 우리의 상황이 어떠어떠하기에 시도해보기로 했다 등) 나름의 근거를 가지고 가설을 세운 부분이 직접 명시되어야 하며 실험한 이후에 이 가설이 유효했는지 아니면 유효하지 않아 다른 어떤 새로운 가설을 세웠는지에 대한 설명이 보완되어야할 것 같습니다. 명확한 이유까지 파악하기 어려운 경우가 있더라도 근거를 제시해야 보다 객관적으로 신뢰할만한 결과가 될 것 같습니다.
-EDA 및 전처리 과정에서 각각의 시각화를 통해 데이터의 분포 특징에 대해 어떤 해석을 도출해냈는지에 대해 같이 설명되었으면 더 좋을 것 같습니다.
-논문 인용 방식이 저널처럼 엄격하게 지켜질 필요는 없으나 일관성있게 통일되면 더 좋을 것 같습니다.
-중복 데이터/오태깅 데이터의 경우 각각의 사례를 간단히 포함시켜도 좋을 것 같습니다.
-(마이너한 부분이지만) 중간에 코드를 캡처 이미지로 삽입한 부분이 있는데 리포트의 배경이 흰색이니 테마를 다크모드로 하는 것보다는 동일하게 흰색으로 하는 것이 독자에게 가독성이 좋을 것 같습니다.
-대회에서는 이 부분까지 고려할 필요는 없지만 최종 프로젝트에서는 이 프로젝트가 어떤 비즈니스적인 가치를 가지고 실제 활용될 수 있을지 use case에 대한 시나리오가 제시되면 더 풍성한 발표가 될 것 같습니다.

지난 5주동안 적극적으로 해주셔서 감사합니다 :)
마지막까지 처음 마음가짐 유지하시면서 좋은 결실 거두시길 바랍니다!


</details>

</br>

## 👋 팀원 소개
### Members
|김남현|민원식|전태양|정기원|주정호|최지민|
|:-:|:-:|:-:|:-:|:-:|:-:|
|<img src='https://avatars.githubusercontent.com/u/54979241?v=4' height=80 width=80px></img>|<img src='https://user-images.githubusercontent.com/73579424/164642795-b5413071-8b14-458d-8d57-a2e32e72f7f9.png' height=80 width=80px></img>|<img src='https://avatars.githubusercontent.com/u/55140109?v=4' height=80 width=80px></img>|<img src='https://user-images.githubusercontent.com/73579424/164643061-599b9409-dc21-4f7a-8c72-b5d5dbfe9fab.jpg' height=80 width=80px></img>|<img src='https://user-images.githubusercontent.com/73579424/164643280-b0981ca3-528a-4c68-9331-b8f7a1cbe414.jpg' height=80 width=80px></img>|<img src='https://avatars.githubusercontent.com/u/97524127?v=4' height=80 width=80px></img>|
|[Github](https://github.com/NHRWV)|[Github](https://github.com/wertat)|[Github](https://github.com/JEONSUN)|[Github](https://github.com/greenare)|[Github](https://github.com/jujeongho0)|[Github](https://github.com/timmyeos)|

<br>

# 🏆 문장 내 개체간 관계 추출

> 문장, 단어에 대한 정보를 통해 ,문장 속에서 단어 사이의 관계를 추론하는 Task

## Result
- Public(11팀 中 2등)
![1 (15)](https://user-images.githubusercontent.com/62659407/162708823-5ea5f4b8-5d7d-4021-9d6a-4300b851c001.png)
- Private(11팀 中 3등)
![1 (16)](https://user-images.githubusercontent.com/62659407/162708852-9bfdb2bf-649d-427a-98d2-d471a7861704.png)

## Dataset 
![16bc4f53-f355-4b9d-968f-657bb5d9b5e5](https://user-images.githubusercontent.com/62659407/162699051-871a1d3a-f249-4d90-a9da-83334e0af681.png)
- train.csv: 총 32470개
- test_data.csv: 총 7765개

**Class Description** <br>
<img src='https://user-images.githubusercontent.com/62659407/162699171-4006c2f6-739f-493a-9bef-f06d23f2a11e.png' height="400">

- 데이터 관련 작업
    - 중복 데이터(84개), 오태깅 데이터(5개) 확인 후 제거
    - 데이터 교정 : 학습 데이터 중 `subj_type`, `obj_type`, `label` 이 잘못된 데이터를 교정 → 오히려 성능이 떨어져 원래의 학습 데이터를 사용
    - 데이터 증강: 논문 "[EDA: Easy Data Augmentation Techniques for Boosting Performance on
Text Classification Tasks](https://arxiv.org/pdf/1901.11196.pdf)"참고, KoEDA 라이브러리를 사용하여 Random Insertion, Random Deletion, Random Swap, Synonym Replacement 적용 → 성능 개선 효과 없었음

- Preprocess
    
    - Typed Entity marker(punct) + Query
        - Typed Entity marker(punct): 논문 “[An Improved Baseline for Sentence-level Relation Extraction](https://arxiv.org/abs/2102.01373)” 참고
            ![1 (11)](https://user-images.githubusercontent.com/62659407/162708505-4830f879-26e8-4850-9639-41a729ac3665.png)
        - Query: 논문 “[BERT: Pre-training of Deep Bidirectional Transformers for
        Language Understanding](https://arxiv.org/abs/1810.04805)” 참고하여 BERT의 Pretain 방식과 유사한 input으로 만들어줌 <br>
   ![1 (12)](https://user-images.githubusercontent.com/62659407/162708551-bc264b6c-1637-48b3-b8c6-434782f87f59.png)
        
          원본 : 〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.
          
          → Typed Entity marker(punct) : 〈Something〉는 # ^ [PER] ^ 조지 해리슨 # 이 쓰고 @ * [PER] * 비틀즈 @ 가 1969년 앨범 《Abbey Road》에 담은 노래다. <br>
          → Query : @ * [PER] * 비틀즈 @ 와 # ^ [PER] ^ 조지 해리슨 # 의 관계 
        
          ⇒ `[CLS]` @ * [PER] * 비틀즈 @ 와 # ^ [PER] ^ 조지 해리슨 # 의 관계 `[SEP]` 〈Something〉는 # ^ [PER] ^ 조지 해리슨 # 이 쓰고 @ * [PER] * 비틀즈 @ 가 1969년 앨범 《Abbey Road》에 담은 노래다. `[SEP]`
        
        
    - Backtranslation : Selenium을 활용한 크롤링을 통해 한국어 → 영어 → 한국어 번역
        
        
        원본 : 〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.
        
        → "Something" is a song written by George Harrison and included by the Beatles on their 1969 album Abbey Road.
        
        ⇒ "Something"은 조지 해리슨이 작곡하고 비틀즈가 1969년 앨범 Abbey Road에 포함시킨 노래입니다.
        
        : 생성 문장을 살펴보면 저품질 문장이 많음
 

## Model
- Pretrained Model: **klue/roberta-large**

- Additional Layer
    | | AutoModelFor SequenceClassification | FC | BiLSTM | BiGRU | BiGRU + Multi-Head-Attention + BiGRU |
    |-|:-:|:-:|:-:|:-:|:-:|
    |모델| <img src='https://user-images.githubusercontent.com/62659407/162708635-e991cd6a-abf4-422a-b38e-8db222b33888.png' width="200">|<img src='https://user-images.githubusercontent.com/62659407/162708661-6e68cfa8-b96a-4577-bca1-c1196ad28f21.png' width="250">|<img src='https://user-images.githubusercontent.com/62659407/162708678-68339a19-00ba-4fd3-9626-4b7fa7881fa0.png' width="250">|<img src='https://user-images.githubusercontent.com/62659407/162708706-83b17d1b-d9cb-426a-84db-8832db12c1d6.png' width="250"> |<img src='https://user-images.githubusercontent.com/62659407/162708738-50e3250c-4f6f-4dbd-9be6-085e2ff0da3f.png' width="250"> <br> - [논문](http://ceur-ws.org/Vol-2421/HAHA_paper_10.pdf) 참고|
    |micro f1| 74.9% | 74.3% | **75.6%** | 75.1% | 74.4% |

- Hyper Parameter
    - Learning Rate : 3e - 5
        - warmup_ratio : 0.1
        - decay to 0
        - weight decay : 0.01 (overfitting 방지)
        → 논문 “[An Improved Baseline for Sentence-level Relation Extraction](https://arxiv.org/abs/2102.01373)” 참고    
    - Batch Size : 64 (Out Of Memory가 일어나지 않는 선에서 Batch Size는 클수록 성능 좋았음)
    - max_len (입력 Sentence의 최대 길이) : 160
    - Epoch : 5
    - Loss Function
        - Cross Entropy
        - Label Smoothing : 0.1 (Class Imbalance 개선)
    - Optimizer : AdamW


- Ensemble
    - **Soft Voting**
        - 리더보드 상위 4개 모델 : **76.7338% (SOTA + 1%)**
        - 5개의 모델 : 75.5%
        - 상위 3개의 모델 : 75.7% (BiLSTM, BiGRU, AutoModelForSequenceClassification)

<br/>

## 프로토타입
![GIF 2022-05-19 오후 1-24-24](https://user-images.githubusercontent.com/62659407/169204992-ab36af27-fd14-4019-86c9-7f84453f79c8.gif)

